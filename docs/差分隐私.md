# ç†µ

## ä¿¡æ¯é‡

ä¿¡æ¯é‡åº¦é‡çš„æ˜¯ä¸€ä¸ªå…·ä½“äº‹ä»¶å‘ç”Ÿæ‰€å¸¦æ¥çš„ä¿¡æ¯ã€‚

å®šä¹‰å¦‚ä¸‹ï¼š
$$
h(x)=-\log _{2} p(x)
$$
ä¿¡æ¯é‡çš„å¤§å°å’Œäº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡æˆåæ¯”ã€‚

## é¦™å†œç†µ

é¦™å†œç†µæ˜¯ç”¨æ¥è¡¡é‡ä¿¡æ¯ä¸ç¡®å®šæ€§çš„æŒ‡æ ‡ï¼Œä¸ç¡®å®šæ€§æ˜¯ä¸€ä¸ªäº‹ä»¶å‡ºç°ä¸åŒç»“æœçš„å¯èƒ½æ€§ã€‚
$$
H[x]=E_{x \sim p}[h(x)]=-E_{x \sim p}[\log p(x)]=-\sum_{x} p(x) \log _{2} p(x)
$$
![](https://gitee.com/wardseptember/images/raw/master/imgs/20201002171621.png)

é¦™å†œç†µä¹Ÿå³ä¿¡æ¯ç†µï¼Œè¡¨ç¤ºç¼–ç æ–¹æ¡ˆå®Œç¾æ—¶ï¼Œæœ€çŸ­å¹³å‡ç¼–ç é•¿åº¦æ˜¯å¤šå°‘ã€‚

## äº¤å‰ç†µ

äº¤å‰ç†µæŒ‡çš„æ˜¯ç¼–ç æ–¹æ¡ˆä¸ä¸€å®šå®Œç¾æ—¶ï¼Œå¹³å‡ç¼–ç é•¿åº¦æ˜¯å¤šå°‘ã€‚

ç°æœ‰å…³äºæ ·æœ¬çš„ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒ$p$å’Œ$q$ï¼Œå…¶ä¸­$p$ä¸ºçœŸå®åˆ†å¸ƒï¼Œ$q$ä¸ºéçœŸå®åˆ†å¸ƒã€‚å¦‚æœä½¿ç”¨é”™è¯¯åˆ†å¸ƒ$q$æ¥è¡¨ç¤ºæ¥è‡ªçœŸå®åˆ†å¸ƒ$p$çš„å¹³å‡ç¼–ç é•¿åº¦ï¼Œåˆ™åº”è¯¥æ˜¯ï¼š
$$
H(p, q)=-\sum_{i=0}^{n} p\left(x_{i}\right) \log \left(q\left(x_{i}\right)\right)
$$

## ç›¸å¯¹ç†µ

ç”±$q$å¾—åˆ°çš„å¹³å‡ç¼–ç é•¿åº¦æ¯”ç”±$p$å¾—åˆ°çš„å¹³å‡ç¼–ç é•¿åº¦å¤šå‡ºçš„ä½æ•°ç§°ä¸ºâ€œç›¸å¯¹ç†µâ€ï¼Œä¹Ÿå«åšKLæ•£åº¦ã€‚KLæ•£åº¦ç”¨äºè¡¡é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼Œå·®å¼‚è¶Šå¤§åˆ™ç›¸å¯¹ç†µè¶Šå¤§ã€‚
$$
D_{K L}(p \| q)=H(p, q)-H(p)=\sum_{i=0}^{n}[p(x_i) *(\log p(x_i)-\log q(x_i))]
$$
ç¼–ç æ–¹æ¡ˆä¸ä¸€å®šå®Œç¾æ—¶ï¼Œå¹³å‡ç¼–ç é•¿åº¦ç›¸å¯¹äºæœ€å°å€¼çš„å¢åŠ å€¼ã€‚

> ç›¸å¯¹ç†µ=äº¤å‰ç†µ-ä¿¡æ¯ç†µ

## ä»»æ„ç†µ

ä»»æ„ç†µæ˜¯é¦™å†œç†µã€Hartleyç†µå’Œæœ€å°ç†µç­‰çš„ä¸€èˆ¬å½¢å¼ã€‚
$$
\mathrm{H}_{\alpha}(x)=\frac{1}{1-\alpha} \log \left(\sum_{i=1}^{n} [p(x_i)]^{\alpha}\right)
$$
å…¶ä¸­$\alpha \geq 0$ å’Œ $\alpha \neq 1$ã€‚

### Hartleyç†µ

å½“$\alpha=0$æ—¶ï¼Œ$\mathrm{H}_{0}(x)$å®é™…ä¸Šå°±æ˜¯hartleyç†µ
$$
\mathrm{H}_{0}(x)=\frac{1}{1-0} \log \left(\sum_{i=1}^{n} p(x_i)^{0}\right)=\log n
$$

### é¦™å†œç†µ

å½“$\alpha \rightarrow 1$æ—¶ï¼Œ$\mathrm{H}_{1}(X)$å®é™…ä¸Šå°±æ˜¯é¦™å†œç†µã€‚
$$
\mathrm{H}_{1}(X)=\lim _{\alpha \rightarrow 1} \frac{1}{-1} \frac{\sum_{i=1}^{n} p(x_i)^{\alpha} \ln p(x_i)}{\left(\sum_{i=1}^{n} p(x_i)^{\alpha}\right)}=-\sum_{i=1}^{n} p(x_i) \ln p(x_i)
$$

## Renyi Divergence

ä»»æ„æ•£åº¦ç”¨äºè¡¡é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚`Renyi Divergence`ä¹Ÿæ˜¯`KL-Divergence`å’Œ`Max-Divergence`çš„æ¨å¹¿ã€‚
$$
D_{\alpha}(P \| Q)=\frac{1}{\alpha-1} \log \left(\sum_{i=1}^{n} q(x_i) \frac{p(x_i)^{\alpha}}{q(x_i)^{\alpha}}\right)
$$
å…¶ä¸­ï¼Œ$P$å’Œ$Q$åˆ†åˆ«è¡¨ç¤ºä¸¤ä¸ªéšæœºå˜é‡ï¼Œä¸”å…¶æ¦‚ç‡åˆ†å¸ƒåˆ†åˆ«ä¸º$ğ‘(ğ‘¥)$ã€$ğ‘(ğ‘¥)$

### KLæ•£åº¦

å½“$\alpha \rightarrow 1$æ—¶ï¼Œä»»æ„æ•£åº¦å°±æ˜¯KLæ•£åº¦
$$
D_{1}(P \| Q)=\lim _{\alpha \rightarrow 1} \frac{1}{\alpha-1} \log \left(\sum_{i=1}^{n} q_{i} \frac{p_{i}^{\alpha}}{q_{i}^{\alpha}}\right)=\sum_{i=1}^{n} p_{i} \log \frac{p_{i}}{q_{i}}
$$

### Max Divergence

å½“$\alpha \rightarrow \infty$æ—¶ï¼Œä»»æ„æ•£åº¦å°±æ˜¯Max Divergence
$$
D_{\infty}(P \| Q)=\lim _{\alpha \rightarrow \infty} \frac{1}{\alpha-1} \log \left(\sum_{i=1}^{n} q_{i} \frac{p_{i}^{\alpha}}{q_{i}^{\alpha}}\right)=\log \max _{i} \frac{p_{i}}{q_{i}}
$$

# Differential privacy

## æ ‡å‡†å·®åˆ†éšç§

A randomized mechanism M: D â†’ R with domain D and range R satisfies (Îµ,Î´)-differential privacy if for any two adjacent inputs d, dâ€² âˆˆ D and for any subset of outputs S âŠ† R it holds that
$$
\operatorname{Pr}[\mathcal{M}(d) \in S] \leq e^{\varepsilon} \operatorname{Pr}\left[\mathcal{M}\left(d^{\prime}\right) \in S\right]+\delta
$$

$$
\mathcal{M}(d) \triangleq f(d)+\mathcal{N}\left(0, S_{f}^{2} \cdot \sigma^{2}\right)
$$

å…¶ä¸­
$$
S_{f} = max(\left|f(d)-f\left(d^{\prime}\right)\right|)
$$


Let $\varepsilon \in(0,1)$ be arbitrary. For $c^{2}>2 \ln (1.25 / \delta),$ the Gaussian Mechanism with parameter $\sigma \geq c \Delta_{2} f / \varepsilon$ is $(\varepsilon, \delta)$ -differentially private.

è¯æ˜ï¼š

### é«˜æ–¯åˆ†å¸ƒ

è‹¥éšæœºå˜é‡ $X$æœä»å‡å€¼ä¸º $Î¼$ï¼Œæ–¹å·®ä¸º$\sigma^{2}$çš„æ­£æ€åˆ†å¸ƒï¼Œè®°ä¸º:
$$
X \sim \mathcal{N}\left(\mu, \sigma^{2}\right)
$$
å…¶æ¦‚ç‡å¯†åº¦å‡½æ•°ä¸ºï¼š
$$
f(x)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}
$$


* L1èŒƒæ•°

    å‡è®¾Xæ˜¯nç»´çš„å‘é‡$X=\left(x_{1}, x_{2}, x_{3}, \ldots x_{n}\right)$ï¼Œ$\|X\|_{1}=\sum_{i=1}^{n} |x_{i}|$

* L2èŒƒæ•°

    å‡è®¾Xæ˜¯nç»´çš„å‘é‡$X=\left(x_{1}, x_{2}, x_{3}, \ldots x_{n}\right)$ï¼Œ$\|X\|_{2}=\sqrt{\sum_{i=1}^{n} x_{i}^{2}}$

L2èŒƒæ•°
$$
\Delta_{2} f=\max _{\mathrm{adjacent} x, y}\|f(x)-f(y)\|_{2}
$$
å‡è®¾$f(x)$æ˜¯å®å€¼å‡½æ•°ï¼Œåˆ™$\Delta f=\Delta_{1} f=\Delta_{2} f$ã€‚

å·®åˆ†éšç§å®šä¹‰å¯ä»¥åŒ–ä¸ºï¼š
$$
|\ln \frac{\operatorname{Pr}[\mathcal{M}(d) \in S]}{\operatorname{Pr}[\mathcal{M}(d^{\prime}) \in S]}| \leq \varepsilon
$$

$$
|\ln \frac{e^{\left(-1 / 2 \sigma^{2}\right) x^{2}}}{e^{\left(-1 / 2 \sigma^{2}\right)(x+\Delta f)^{2}}}| = \mid \frac{1}{2 \sigma^{2}}\left(2 x \Delta f+(\Delta f)^{2}\right)| \leq \varepsilon
$$

$$
x<\sigma^{2} \frac{\varepsilon}{\Delta f}-\Delta f / 2
$$

![](https://gitee.com/wardseptember/images/raw/master/imgs/20201003222026.png)

![](https://gitee.com/wardseptember/images/raw/master/imgs/20201003222103.png)

![](https://gitee.com/wardseptember/images/raw/master/imgs/20201003222125.png)

![](https://gitee.com/wardseptember/images/raw/master/imgs/20201003222158.png)

## ä»»æ„å·®åˆ†éšç§

### ä»»æ„æ•£åº¦

Let $P$ and $Q$ be two distributions on $\mathcal{X}$ defined over the same probability space, and let p and q be their respective densities. The RÃ©nyi divergence of a finite order $\alpha \neq 1$ between $P$
and $Q$ is defined asï¼š
$$
\mathrm{D}_{\alpha}(P \| Q) \triangleq \frac{1}{\alpha-1} \ln \int_{\mathcal{X}} q(x)\left(\frac{p(x)}{q(x)}\right)^{\alpha} \mathrm{d} x
$$

### Re Ìnyi differential privacy(RDP)

We say that a randomized mechanism $\mathcal{M}: \mathcal{S} \rightarrow \mathcal{R}$ satisfies $(\alpha, \varepsilon)-$RÃ©nyi differential privacy $(R D P)$ if for any two adjacent inputs $S, S^{\prime} \in \mathcal{S}$ it holds that:
$$
\mathrm{D}_{\alpha}\left(\mathcal{M}(S) \| \mathcal{M}\left(S^{\prime}\right)\right) \leq \varepsilon
$$
å…¶ä¸­$S^{\prime}=S \cup\{x\}$


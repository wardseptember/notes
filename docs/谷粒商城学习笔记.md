# TODO

stream流学习

旧：192.168.43.187

更换数据库

192.168.200.153   --- > 192.168.31.171

# 启动

启动nacos-1,启动gateway

启动renren-fast-vue

启动renrenApplication



进度：55

# mysql

安装

```shell
docker run -p 3306:3306 --name JY_mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql
 docker exec -it cf0e056371f9 /bin/bash  进入mysql交互
```

# redis

安装

```
docker run -p 6379:6379 --name redis -v /mydata/redis/data:/data -v /mydata/redis/conf/redis.conf:/etc/redis/redis.conf --privileged=true -d d4f259423416 redis-server /etc/redis/redis.conf

docker run -p 6379:6379 -d d4f259423416 redis-server

docker exec -it 22873cd482a3 redis-cli
sudo docker update redis --restart=always
```

# nacos

```shell
sh startup.sh -m standalone     # 启动nacos, 单机版

http://127.0.0.1:8848/nacos/
```

# Picgo

```shell
picgo upload  # 上传剪切板内容，上传后自动复制到剪切板
```

# vue

```shell
问题：Node Sass does not yet support your current environment: OS X 64-bit with Unsupported runtime
参考：https://blog.csdn.net/yaya07755/article/details/96834875
解决：
1.先卸载
npm uninstall --save node-sass

2.清除缓存
npm cache clean -f

3.升级node-sass模块
npm install --save node-sass


快捷键
httppost
httpget
```

# mybatis

## 逻辑删除

* 配置全局的逻辑删除规则
* 配置逻辑删除的组件Bean，高版本可省略
* 给Bean加上逻辑删除注解@TableLogic

# 数据校验

Jsr303



分组校验

```

@Validated({UpdateGroup.class})
```



# 一些报错

p100集规格报错

```sql
INSERT INTO sys_menu (menu_id, parent_id, name, url, perms, type, icon, order_num) VALUES (76, 37, '规格维护', 'product/attrupdate', '', 2, 'log', 0);
```

# ES

9200 9300

kibana是ES的可视化界面

http://192.168.31.171:5601/app/kibana#?_g=()



https://easydoc.xyz/s/78237135/ZUqEdvA4/Tpz10eVn





https://github.com/cosmoswong/gulimall

# 本机ip

 192.168.31.219

# 优化

## 动静分离

动态请求经过网关，静态不经过，直接放在nginx里面。

## redis

### 读模式

* 缓存穿透：查询一个null数据，解决：缓存空数据
* 缓存击穿：大量并发进来同时查询一个正好过期的数据，解决：加锁，分布式锁
* 缓存雪崩：大量的key同时过期，解决：加随机时间

### 写模式

* 读写加锁
* 引入canal，感知到mysql的更新去更新数据库
* 读多写多，直接去查数据库

总结：

常规数据(读多写少，即时性，一致性要求不高的数据)，完全可以使用spring-cache.





属性：

* CPU品牌
* CPU型号



创建线程的方式：

* 继承Thread
* 实现Runable接口
* 实现Callable接口+FutureTask
* 线程池



# 分布式Session

session存到redis中，整合springsession





## ES

迁移数据

```
POST _reindex
{
  "source": {
    "index": "product"
  },
  "dest": {
    "index": "gulimall_product"
  }
}
```

# 购物车

* 离线购物车

Cookie 存一个user-key，标识用户身份

第一次访问，没有user-key，创建一个user-key，存到cookie中；并把用户信息存到threadlocal中

商品信息存到redis中，

```java
String cartKey = !ObjectUtils.isEmpty(userInfoTO.getUserId()) ? CART_PREFIX + userInfoTO.getUserId() : CART_PREFIX + userInfoTO.getUserKey();

```



* 在线购物车

使用ThreadLocal共享数据，同一个用户请求，都用的同一个线程。

将临时购物车数据合并到在线购物车中



# Feign远程调用丢失请求头

feign进行远程调用会经过一系列拦截器，创建一个新的request，里面没有任何请求头，

解决：

加上Feign远程调用拦截器，

```java
@Configuration
public class GulimallFeignConfig {
    @Bean("requestInterceptor")
    public RequestInterceptor requestInterceptor() {
        return template -> {
            ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
            if (!ObjectUtils.isEmpty(requestAttributes)) {
                HttpServletRequest request = requestAttributes.getRequest();// 老请求
                if (!ObjectUtils.isEmpty(request)) {
                    String cookie = request.getHeader("Cookie");
                    template.header("Cookie", cookie);
                }
            }
        };
    }
}
```

## Feign异步远程调用丢失请求头

```java
        RequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();

        CompletableFuture<Void> getAddressedTask = CompletableFuture.runAsync(() -> {
            // 1 远程查询会员的所有列表
            RequestContextHolder.setRequestAttributes(requestAttributes);
            List<MemberAddressVO> addresses = memberFeignService.getAddresses(memberResponseVO.getId());
            orderConfirmVO.setAddresses(addresses);
        }, threadPoolExecutor);
```

# 订单

接口幂等性，防止订单重复提交

接口幂等性：用户发起一次请求和多次请求结果一致

幂等性解决：

* token机制

* 各种锁机制
* 各种唯一约束
* 防重表
* 全局唯一请求ID，防重令牌，存在页面和redis



难点：

1. 远程锁库存假异常，远程服务执行成功，由于网络故障等没返回，订单回滚，但库存减了

2. 远程服务执行成功，返回成功，以后代码出异常，无法回滚

分布式事务解决上面两个问题。

* 

```
spring.application.name=gulimall-seckill
server.port=25000
spring.thymeleaf.cache=false

spring.session.store-type=redis

spring.redis.host=192.168.31.171
spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848
spring.cloud.nacos.config.server-addr=127.0.0.1:8848
```

# 定时任务





# sentinel



# sleuth + zipkin





* 缓存
* 异步
* 队排好





# 重点

实现功能：

* 后台管理系统

* 登录注册、单点登录和社交登录
* 查询(ES)
* 离线购物车和在线购物车，结算
* 秒杀功能
* redis缓存商品分类数据

## 数据校验

后端JSR303校验

## redis

### 缓存击穿、穿透、雪崩

| 类型     | 描述                                                         | 解决                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 缓存击穿 | 对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。如果这个 key 在大量请求同时进来前正好失效，那么所有对这个 key 的数据査询都落到db. | 加锁。大量并发只让一个去查，其他人等待，査到以后释放锁，其他人获取到锁，先查缓存，就会有数据，不用去 db |
| 缓存穿透 | 指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查询的null写入缓存，这将导致这个不存在的数据每次请求都要到存储层去査询，失去了缓存的意义。利用不存在的数据进行攻击，数据库瞬时压力增大，最终导致崩溃 | nul 结果缓存，并加入短暂过期时间                             |
| 缓存雪崩 | 缓存雪崩是指在我们设置缓存时 key 采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到 DB, DB 瞬时压力过重雪崩。 | 原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 |





## Nginx

1. nginx做动静分离

将网站静态资源(HTML，JavaScript，CSS，Images 等文件)与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问，减轻后台服务的压力。这里需要将静态资源放到 nginx 中，动态资源转发到 tomcat 服务器中。

2. nginx代理给网关，会丢失请求的host信息，手动设置`proxy_set_header Host $host`

```
http {
    upstream catmall{
       server 127.0.0.1:8888;
    }

    server {
        listen       80;
        server_name  gulimall.com;

        location / {
	        proxy_set_header HOST $host;
	        proxy_pass http://gulimall.com;
            #root   html;
            #index  index.html index.htm;
        }
    }

    include servers/*;
}
```

### 反向代理

- 正向代理：代理与客户端在一个局域网中，隐藏客户端，假装自己是客户端，对 Server 透明。
- 反向代理：代理与服务器在一个局域网中，隐藏服务端，假装自己是服务端，对 Client 透明。
    - 反向代理（Reverse Proxy）实际运行方式是以代理服务器来接受来自 internet 的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个服务器。
    - 可以保证内网的安全
    - 可以实现负载均衡，优化网络负载。

### 负载均衡

主要还是为了实现高并发，在以往的小型项目中，用户量小，并发量小时，一台服务器可能就勉强够用了，但是现在项目越来越大，也越来越偏向微服务架构，每个服务都需要许多台机器来提供支持。这个时候就需要实现负载均衡，而 Nginx 又比较适合在高并发的场景下工作，它作为反向代理，可以接受大量 Client 的请求，然后进行任务分发(指派服务器)。

- 负载均衡的目的就是为了减轻单个服务节点的压力，避免 Web 响应过慢，避免出现宕机。

#### Nginx 负载均衡策略

**内置有三种：轮询、加权、IP 绑定**

- 轮询：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某个服务器宕机，能自动剔除故障系统。

```
upstream backserver { 
	server 192.168.0.12; 
	server 192.168.0.13; 
}
```

- 加权 weight：指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。

```
upstream backserver { 
    server 192.168.0.14 weight=8; 
    server 192.168.0.15 weight=10; 
} 
```

- IP 绑定 ip_hash：每个请求按访问 ip 的 hash 结果分配，每个访客固定访问一个后端服务器，可以解决 session 共享的问题。

```
upstream backserver { 
	ip_hash; 
    server 192.168.0.12:88; 
    server 192.168.0.13:80; 
} 
```

**第三方插件两种：fair、url_hash**

- fair：需要安装 upstream_fair 模块。可以根据页面大小和加载时间只能地进行负载均衡，响应时间短的优先分配。

```
upstream backserver { 
    server server1; 
    server server2; 
    fair; 
} 
```

- url_hash：需要安装 nginx 的 hash 软件包。利用 url 的 hash 结果分配，使每个 url 定向到同一台后端服务器。

```
upstream backserver { 
    server squid1:3128; 
    server squid2:3128; 
    hash $request_uri; 
    hash_method crc32; 
} 
```

### 限流算法

#### 漏桶算法

漏桶算法(Leaky Bucket)的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。

漏桶可以看作是一个带有常量服务时间的单服务器队列，如果漏桶（包缓存）溢出，那么数据包会被丢弃。 在网络中，漏桶算法可以**控制端口的流量输出速率**。

如图所示，把请求比作是水，水来了都先放进桶里，并以限定的速度出水，当水来得过猛而出水不够快时就会导致水直接溢出，即拒绝服务。

可以看出，漏桶算法可以很好的控制流量的访问速度，一旦超过该速度就拒绝服务。

![](https://gitee.com/wardseptember/images/raw/master/imgs/20200917160239.png)

#### 令牌桶算法

令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。

令牌桶算法的原理：系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。**如果令牌消耗速率小于生产令牌的速度，令牌就会一直产生直至装满整个令牌桶。**

![](https://gitee.com/wardseptember/images/raw/master/imgs/20200917160258.png)

从原理上看，令牌桶算法和漏桶算法是相反的，一个“进水”，一个是“漏水”。

Google 的 Guava 包中的 RateLimiter 类就是令牌桶算法的解决方案。

### 比较

漏桶算法与令牌桶算法的区别在于

- 漏桶算法能够强行限制数据的传输速率。
- 令牌桶算法能够在限制数据的平均传输速率的同时还允许某种程度的突发传输。

在某些情况下，漏桶算法不能够有效地使用网络资源，因为漏桶的漏出速率是固定的，所以即使网络中没有发生拥塞，漏桶算法也不能使某一个单独的数据流达到端口速率。

因此，漏桶算法对于存在突发特性的流量来说缺乏效率。而令牌桶算法则能够满足这些具有突发特性的流量。通常，漏桶算法与令牌桶算法结合起来为网络流量提供更高效的控制。

### Nginx 如何限流？

在开发高并发系统时有三把利器用来保护系统：缓存、降级和限流

- 缓存：目的是提升系统访问速度和增大系统处理容量。
- 降级：当服务器压力剧增的情况时，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行
- 限流：通过对并发访问/请求进行限速，或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务、排队或等待、降级等处理。



## 性能压测

### 基本概念

- HPS(Hits Per Second): 每秒点击次数
- TPS(Transaction Per Second)
- QPS(Query Per Second)
- 最大响应时间
- 最少响应时间
- 90%响应时间

## 异步

### `CompletableFuture<T>`

#### 业务场景

- 获取SKU基本信息
- 获取SKU图片信息
- 获取SKU促销信息
- 获取SPU所有销售属性
- 获取规格参数组及组下的规格参数
- SPU详情

## 购物车

用户可以在登录状态下将商品加入在线购物车，数据存储在redis中

用户可以在未登录状态下将商品加入离线购物车，数据存储在redis中，即使浏览器关闭，离线购物车数据都在。登录以后会将临时购物车中的数据合并过来。

> 京东给每个用户生成一个值类似于UUID的`user-key`，有效期一个月，存储在`Cookie`，浏览器保存以后，每次访问都会带上这个`cookie`。
>
> 登录后：`session`有用户信息
>
> 未登录：`cookie`中的`user-key`
>
> 第一次使用时，如果没有临时用户，帮忙创建一个临时用户。

## ThreadLocal用户身份鉴别

- `public class CartInterceptor implements HandlerInterceptor{}`重写`preHandle, postHandle` ，不用加`@Component`
- 添加`MallWebConfig`

```
@Configuration
public class MallWebConfig implements WebMvcConfigurer {
    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(new CartInterceptor()).addPathPatterns("/**");
    }
}
```

使用ThreadLocal，同一个请求，只有一个线程处理，可以方便地或者session、cookie等信息。

## RabbitMQ

消息：消息头 消息体 路由键

消息的生产者

交换机，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。

broker是消息代理

Exchange类型

* direct是直接点对点的交互接，
* fanout是广播交换机，无论路由键是什么，全部queue都能收到
* topic是主题交换机，可以匹配主题的
* header也是点对点，效率低，不使用

<div align="center"> <img src="https://gitee.com/wardseptember/images/raw/master/imgs/20201024214352.png" width="600"/> </div><br>

### 特点

* 一个客户端只会建立一个长链接，长连接里面可以有很多channel
* 消息发布者是将消息发给exchange，exchange将消息分发给queue，channel对接上queue就可以接受消息了
* Broker里面可以有多个虚拟主机，各个虚拟主机之间互不影响。
* Exchange和queue之间靠binding连接着，binding决定交换机的消息应该发送到那个队列
* exchange也可以跟exchange绑定
* 消息中的路由键如果和Binding中的binding key一致，交换机就将消息发送到对应的队列中。

```
docker run -d --name rabbitmq -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 25672:25672 -p 15671:15671 -p 15672:15672 rabbitmq:management

docker update rabbitmq --restart=always
```

一些点

* @RabbitLister 可以标注在类和方法上，监听哪些队列即可
* @RabbitHandler： 标在方法上，重载区分不同消息

<div align="center"> <img src="https://gitee.com/wardseptember/images/raw/master/imgs/20201024215037.png" width="600"/> </div><br>

### 应用

- 异步处理
- 应用解耦
- 流量控制(削峰、填谷)

### 消息确认机制

使用可靠消息实现最终一致性。

保证消息可靠抵达

publisher到broker会确认

exchange到queue会确认

queue到consumer会确认

![](https://gitee.com/wardseptember/images/raw/master/imgs/20200917212340.png)

## 提交订单

接口幂等性：用户对同一操作发起的一次请求或者多次请求的结果都是一致的。

问题：

* 用户多次点击按钮提交
* 用户页面回退再次提交
* 微服务互相调用，由于网络问题，导致请求失败，feign触发重试机制。

解决：

> 下单 去创建订单 验证令牌 核算价格 锁定库存

### 防止重复提交

来到订单页的时候，页面加入防重令牌，并且redis中存入防重令牌，提交订单时获取令牌、比较、删令牌原子操作

```java
        SubmitOrderResponseVO responseVO = new SubmitOrderResponseVO();
        MemberResponseVO memberResponseVO = LoginUserInterceptor.loginUser.get();
        responseVO.setCode(0);
        String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
        String orderToken = submitVO.getOrderToken();
        // 原子性操作验证和删除令牌
        Long result = stringRedisTemplate.execute(new DefaultRedisScript<>(script, Long.class),
                Collections.singletonList(OrderConstant.USER_ORDER_TOKEN_PREFIX + memberResponseVO.getId()), orderToken);
```

### 核算价格

把提交的总价格和购物车中的所有项的价格对比

### 锁定库存

可靠消息加最终一致性

## Feign远程调用丢失请求头问题

`Feign`在远程调用之前要构造请求，此时会丢失请求头`headers`，`request`中包含许多拦截器。

在构建新请求的时候需要吧“老请求”中的数据获取并保存传递到新请求中。

```java
@Configuration
public class MallFeignConfig {
    @Bean("requestInterceptor")
    public RequestInterceptor requestInterceptor() {
        return new RequestInterceptor() {
            @Override
            public void apply(RequestTemplate template) {
                ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
                String cookie = requestAttributes.getRequest().getHeader("Cookie");
                template.header("Cookie", cookie);
            }
        };
    }
}
```

## Feign异步编排丢失请求头问题

- 原因：因为`RequestContextHolder`中的`ThreadLocal`只在当前线程可用，线程间独立，而在异步编排时会创建不同的线程执行任务，`ThreadLocal`中的数据将会丢失。
- 解决办法：在异步编排前首先获取`RequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();`，然后在异步任务开始前重新设置进去，`RequestContextHolder.setRequestAttributes(requestAttributes);`

## 分布式事务

CAP定理

- C: 一致性，在分布式系统中的所有数据备份，在同一时刻是否有同样的值。
- A: 可用性，集群一部分结点故障后，集群整体是否还能响应客户端的读写请求。
- P: 分区容错性，大多数分布式系统都分布在多个子网络，每个子网络就叫做一个区，分区容错的意思是，区间通信可能失败。机器故障、网络故障、机房停电等异常情况下仍然能够满足一致性或者可用性。
- CAP定理指的是以上三点至多只能同时保证两点，不能三者兼顾，一般来说在分布式系统中P不可避免，所以一个系统至多只能包租CP或AP。

保持一致性，[raft算法](http://thesecretlivesofdata.com/raft/)

### BASE理论

* 基本可用
* 软状态，
* 最终一致性

### 常见解决方案

1. 2PC模式，性能差
2. 柔性事务，写三份代码，try、confirm、cancel
3. 最大努力通知型方案
4. 可靠消息+最终一致性方案

### 谷粒商城采用方案

使用延时队列，实现最终一致性。

解锁库存：

* 下单成功，库存锁定成功，接下来的业务失败，需要解锁库存
* 下单成功，30min未付款

## 消息积压、重复、丢失等问题解决方案

- 消息丢失

    - 消息发送出去，由于网络问题没有抵达服务器
        - 做好容错方法(`try-catch`)，发送消息可能会网络失败，失败后要有重试机制，可记录到系统数据库，采用定期扫描重发的方式。
        - 做好日志记录，每个消息状态是否都被服务器收到都应该被记录
        - 做好定期重发，如果消息没有发送成功，定期去数据库扫描未成功的消息进行重发

    - 消息抵达Broker，Broker要将消息写入磁盘才算成功，此时Broker尚未持久化完成，宕机。
        - `publisher`必须加入确认回调机制，确认成功的消息，修改数据库消息状态
    - 自从ACK状态下，消费者收到消息，但没来得及消费便宕机
        - 一定开启手动`ACK`，消息成功才移除，失败或者没来得及处理就`noACK`并重新入队。

- 消息重复
    - 消息消费成功，事务已经提交，`ack`时，机器宕机，导致没有`ack`成功，`Broker`的消息重新由`unack-> ready`，并发送给其他消费者。
    - 消息消费失败，由于重试机制，自动又将消息发送出去。
    - 成功消费，ack时宕机，消息由unack变为ready，Broker又重新发送
        - 消费者的业务消费接口应该设计成幂等性的，比如扣库存工作单的状态标志
        - 使用 **防重表(redis, mysql)** ，发送消息每一个都有业务的唯一标识，处理过就不用再处理。
        - `RabbitMQ`的每一个消息都有`redelivered`字段，可以获取消息是否是被重新投递的。
- 消息积压
    - 消费者宕机积压
    - 消费者消费能力不足积压
    - 发送者发送流量太大
        - 上线更多的消费者，进行正常消费。
        - 上线专门的队列消费服务，将消息先批量取出来，记录数据库，离线慢慢处理。





# 2020.10.21

* 后台管理系统
* 购物车、订单、结算、库存、秒杀
* 分布式事务、分布式锁
* 高并发：线程池、异步编排
* 商品服务、优惠服务、用户服务、仓储服务、秒杀服务、订单服务、检索服务、购物车服务



客户端发送请求给nginx，nginx把请求转交给api网关，网关把请求动态路由到指定服务，

nginx代理给网关的时候，会丢失请求的host信息。

# 缓存

适合放入缓存：

* 即时性、数据一致性要求不高的
* 访问量大且更新频率不高的数据

本地缓存map，会存在数据不一致情况

分布式缓存

Data-redis 使用lettuce，lettuce的bug，使用jedis代替lettuce。

## 分布式锁

### 第一阶段

set key value NX

nx只有key不存在的时候才会设置key的值

<div align="center"> <img src="https://gitee.com/wardseptember/images/raw/master/imgs/20201022195307.png" width="600"/> </div><br>

问题：

* 没有执行删除锁代码，产生死锁

解决：

* 设置锁过期时间，过期自动解锁。

如果设置过期时间代码没执行，一样死锁。加锁和设置过期时间要原子操作。

```
set lock 111 EX 300 NX
```

还存在的问题：

* 业务执行时间长，锁自动过期了，
* 把别人的锁删除了

解决：

* 占锁的时候，值指定为uuid，每个人匹配是自己锁才删除。获取锁的值和删除锁也要原子操作。

最后存在的问题就是没有锁的自动续期，需要把过期时间设置长一点。

## Redisson

锁的自动续期，不用担心业务时间长，锁被释放。加锁业务完成就不会自动续期。

如果指定了锁的过期时间就不会自动续期。

## 缓存一致性

双写模式，改完数据重新缓存

* 脏数据
* 解锁解决

失效模式，改完数据删除缓存

* 脏数据

终极解决canal

## spring cache

Cachemanager 管理多个cache

* Cacheable：触发将数据保存到缓存的操作
* CacheEvict: 触发将数据从缓存删除的操作
* CachePut: 不影响方法执行更新缓存
* Caching: 组合以上多个操作
* CacheConfig: 在类级别共享缓存的相同配置

```
@EnableCaching
```

### 自定义配置

```java
package com.atguigu.gulimall.product.config;

import org.springframework.boot.autoconfigure.cache.CacheProperties;
import org.springframework.boot.context.properties.EnableConfigurationProperties;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.cache.RedisCacheConfiguration;
import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.RedisSerializationContext;
import org.springframework.data.redis.serializer.StringRedisSerializer;

/**
 * @author wardseptember
 * @create 2020-09-06 14:13
 */
@EnableConfigurationProperties(CacheProperties.class)
@EnableCaching
@Configuration
public class MyCacheConfig {

    @Bean
    public RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties) {
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig();
        config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
        config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));

        CacheProperties.Redis redisProperties = cacheProperties.getRedis();

        if (redisProperties.getTimeToLive() != null) {
            config = config.entryTtl(redisProperties.getTimeToLive());
        }
        if (redisProperties.getKeyPrefix() != null) {
            config = config.prefixKeysWith(redisProperties.getKeyPrefix());
        }
        if (!redisProperties.isCacheNullValues()) {
            config = config.disableCachingNullValues();
        }
        if (!redisProperties.isUseKeyPrefix()) {
            config = config.disableKeyPrefix();
        }
        return config;
    }
}

```

### 存在问题

缓存击穿没解决，本地锁

缓存雪崩

# 异步

`CompletableFuture<T>`

业务场景

- 获取SKU基本信息
- 获取SKU图片信息
- 获取SKU促销信息
- 获取SPU所有销售属性
- 获取规格参数组及组下的规格参数
- SPU详情

```
public static CompletableFuture<Void> runAsync(Runnable runnable,
                                                   Executor executor) {
```

没有返回值

```
    public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier,
                                                       Executor executor) {
        return asyncSupplyStage(screenExecutor(executor), supplier);
    }
```

有返回值



```java
    @Override
    public SkuItemVo item(Long skuId) throws ExecutionException, InterruptedException {
        SkuItemVo skuItemVo = new SkuItemVo();

        CompletableFuture<SkuInfoEntity> infoFuture = CompletableFuture.supplyAsync(() -> {
            //1. SKU基本信息获取，pms_sku_info
            SkuInfoEntity byId = this.getById(skuId);
            skuItemVo.setInfo(byId);
            return byId;
        },executor);

        CompletableFuture<Void> saleFuture = infoFuture.thenAcceptAsync((res) -> {
            //3. 获取SPU销售属性组合 pms_product_attr_value
            List<SkuItemSaleAttrVo> skuItemSaleAttrVos = skuSaleAttrValueService.getSaleAttrsBySpuId(res.getSpuId());
            skuItemVo.setSaleAttr(skuItemSaleAttrVos);
        }, executor);

        CompletableFuture<Void> descFuture = infoFuture.thenAcceptAsync((res) -> {
            //4. 获取SPU的介绍 pms_spu_info_desc
            SpuInfoDescEntity spuInfoDescEntity = spuInfoDescService.getById(res.getSpuId());
            skuItemVo.setDesp(spuInfoDescEntity);
        }, executor);

        CompletableFuture<Void> baseFuture = infoFuture.thenAcceptAsync((res) -> {
            //5. 获取SPU的规格参数信息
            List<SpuItemAttrGroupVo> spuItemAttrGroupVos = attrGroupService.getAttrGroupWithAttrsBySpuId(res.getSpuId(), res.getCatalogId());
            skuItemVo.setGroupAttrs(spuItemAttrGroupVos);
        }, executor);

        CompletableFuture<Void> imagesFuture = CompletableFuture.runAsync(() -> {
            //2.SKU的图片信息获取，pms_sku_images
            List<SkuImagesEntity> skuImagesEntities = imagesService.getImagesBySkuId(skuId);
            skuItemVo.setImages(skuImagesEntities);
        }, executor);

        CompletableFuture<Void> seckillFuture = CompletableFuture.runAsync(() -> {
            R skuSeckillInfo = seckillFeignService.getSkuSeckillInfo(skuId);
            if (skuSeckillInfo.getCode() == 0) {
                SeckillInfoVo seckillInfoVo = skuSeckillInfo.getData(new TypeReference<SeckillInfoVo>() {
                });
                skuItemVo.setSeckillInfoVo(seckillInfoVo);
            }
        }, executor);



        CompletableFuture.allOf(infoFuture, saleFuture, descFuture, baseFuture, imagesFuture, seckillFuture).get();
        return skuItemVo;
    }
```

# 短信验证码

整合第三方，传入验证码和手机号即可，注册时校验 验证码是否匹配。

验证码提供给别的服务进行调用，

## 接口防刷

把验证码存到redis中，key为AuthServerConstant.SMS_CODE_CACHE_PREFIX + phone，值为验证码+当前系统时间

每次请求过来都校验一下，当前系统时间和Redis存的时间差，是否大于60秒，大于再发验证码，不大于返回提示消息

```java
    @GetMapping("/sms/send")
    @ResponseBody
    public R sendSMS(@RequestParam("phone") String phone) {

        String redisCode = stringRedisTemplate.opsForValue().get(AuthServerConstant.SMS_CODE_CACHE_PREFIX + phone);
        if (!StringUtils.isEmpty(redisCode)) {
            long l = Long.parseLong(redisCode.split("_")[1]);
            if (System.currentTimeMillis() - l < 60000) {
                return R.error(BizCodeEnum.SMS_CODE_EXCEPTION.getCode(), BizCodeEnum.SMS_CODE_EXCEPTION.getMsg());
            }
        }

        String code = UUID.randomUUID().toString().substring(0, 5);
        String redisStorage = code + "_" + System.currentTimeMillis();
        // 为验证码设置过期时间
        stringRedisTemplate.opsForValue().set(AuthServerConstant.SMS_CODE_CACHE_PREFIX + phone, redisStorage, 10, TimeUnit.MINUTES);

        thirdPartyFeign.sendSMSCode(phone, code);
        return R.ok();
    }
```

# 注册功能

把密码用md5加密后加盐

用BCryptPasswordEncoder密码加密器，

```java
    @Override
    public MemberEntity login(MemberLoginVO memberLoginVO) {

        String account = memberLoginVO.getAccount();
        String password = memberLoginVO.getPassword();

        // 去数据库查询
        MemberEntity memberEntity = this.baseMapper.selectOne(new QueryWrapper<MemberEntity>()
                .eq("username", account).or().eq("mobile", account));
        if (!ObjectUtils.isEmpty(memberEntity)) {
            String passwordDB = memberEntity.getPassword();
            BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder();
            if (passwordEncoder.matches(password, passwordDB)) {
                return memberEntity;
            } else {
                return null;
            }
        } else {
            return null;
        }
    }
```

# 社交登录

* 引导用户去授权页
* 认证成功，返回令牌
* 用令牌获取信息

<div align="center"> <img src="https://gitee.com/wardseptember/images/raw/master/imgs/20201023215014.png" width="600"/> </div><br>

微博跳回回调页，后台换取access token

```java
    @GetMapping("/oauth2.0/weibo/success")
    public String weibo(@RequestParam("code") String code, HttpSession session) throws Exception {
        Map<String, String> map = new HashMap<>();
        map.put("client_id", "1724306451");
        map.put("client_secret", "768b60b62b4ed4d76f694857cd1bbd11");
        map.put("grant_type", "authorization_code");
        map.put("redirect_uri", "http://auth.gulimall.com/oauth2.0/weibo/success");
        map.put("code", code);
        HttpResponse response = HttpUtils.doPost("https://api.weibo.com", "/oauth2/access_token", "post", new HashMap<>(), map, new HashMap<>());
        if (response.getStatusLine().getStatusCode() == 200) {
            String json = EntityUtils.toString(response.getEntity());
            SocialUser socialUser = JSON.parseObject(json, SocialUser.class);
            // 获取用户的登录平台，然后判断用户是否该注册到系统中
            R r = memberFeignService.oauthLogin(socialUser);
            if (r.getCode() == 0) {
                // session 子域共享问题
                MemberResponseVO loginUser = r.getData(new TypeReference<MemberResponseVO>() {});
                session.setAttribute(AuthServerConstant.LOGIN_USER, loginUser);
                return "redirect:http://gulimall.com";
            } else {
                return "redirect:http://auth.gulimall.com/login.html ";
            }
        } else {
            return "redirect:http://auth.gulimall.com/login.html ";
        }
    }
```

换取到access token后，根据uid查询数据库是否有这个用户，如果有，则更新令牌和过期时间；如果没有，则进行注册。

## session

<div align="center"> <img src="https://gitee.com/wardseptember/images/raw/master/imgs/20201023221215.png" width="600"/> </div><br>

session不能跨不同域名共享，解决：放大域名作用域

```java
@Configuration
public class GulimallSessionConfig {
    @Bean
    public CookieSerializer cookieSerializer() {
        DefaultCookieSerializer cookieSerializer = new DefaultCookieSerializer();
        cookieSerializer.setDomainName("gulimall.com");
        cookieSerializer.setCookieName("GULISEESSION");
        return cookieSerializer;
    }

    @Bean
    public RedisSerializer<Object> springSessionDefaultRedisSerializer() {
        return new GenericJackson2JsonRedisSerializer();
    }
}

```

同一个服务，服务多份，session不同步问题

不同服务，session不能共享问题

解决方案：

spring session ， 用redis存储session

# 单点登录

<div align="center"> <img src="https://gitee.com/wardseptember/images/raw/master/imgs/20201024115900.png" width="600"/> </div><br>

微博登录，新浪网也登录了。

1. 给登录服务器留下登录痕迹
2. 登录服务器将token信息重定向到时候，带到url地址中，并且保存到cookie中
3. 其他系统将token对应的用户保存到自己的session中

pt_key=AAJfk79BADBLdHV4fv8qd3SN0FnWpTzyGQdPDnqTII1qAscGaDFl7pmaKzTuQCTC-kX2fEGjaVU;pt_pin=u_4b940e9f6f429;

